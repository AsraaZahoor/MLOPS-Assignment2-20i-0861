# MLOps Implementation with Apache Airflow

## Objective
Implement Apache Airflow to automate the processes of data extraction, transformation, and version-controlled storage, focusing on data from `dawn.com` and `BBC.com`.

## Overview
This project uses Apache Airflow to orchestrate a workflow that automates the extraction of links, titles, and descriptions from articles on `dawn.com` and `BBC.com`, preprocesses the text data, and stores the transformed data in Google Drive. It also utilizes Data Version Control (DVC) to track versions of the data and metadata.

## Tasks
- **Data Extraction:** Extract links, titles, and descriptions from the landing pages of `dawn.com` and `BBC.com`.
- **Data Transformation:** Clean and format the extracted text data for further analysis.
- **Data Storage and Version Control:** Store the processed data on Google Drive and use DVC to manage data versions, including metadata versioning on GitHub.
- **Apache Airflow DAG Development:** Develop a DAG that automates the extraction, transformation, and storage processes with proper error management and task dependency handling.

## Repository Structure
```plaintext
/
|-- dags/
|   |-- DataExtraction.py            # Airflow DAG script for scheduling and automating tasks
|-- data/
|   |-- extracted.csv            # Extracted data from the websites
|-- logs/
|   |-- airflow_logs.txt         # Logs generated by Airflow during DAG execution
|-- requirements.txt             # Project dependencies
|-- README.md                    # Project documentation and setup instructions
|-- .dvc
